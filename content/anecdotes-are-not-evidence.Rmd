---
title: "Anecdotes Are Not Evidence"
draft: true
date: 2021-01-10
tags: ["fallacies"]
bibliography: "../bibliographies/anecdotes-are-not-evidence.bib"
csl: "../bibliographies/chicago-author-date.csl"
link-citations: true
implicit-figures: true
output:
  blogdown::html_page:
    md_extensions: ["+footnotes"]
    toc: true
    toc_depth: 5
include-before: |
  <p>The opening paragraph goes here.</p>
  <!--more-->
  ## Table of Contents
---

## Introduction

If enough time is spent around those that construe themselves as doing scientific inquiry, one is liable to encounter the maxim "anecdotes are not evidence." Anecdotes are stories that consist either of one's own personal experiences or the retelling of the personal experiences of others. The maxim "anecdotes are not evidence" is a healthy reminder that the use of anecdotes as evidence has numerous flaws.

However, the maxim "anecdotes are not evidence," like all slogans, is a short, catchy phrase and is devoid of any substantially informative content. While such a catch phrase can be used as a mnemonic device to recall deeper understanding, it can also be used without any cognizance of the issues to which it alludes. When used in this latter way, the maxim can be interpreted in ways that lead to implications that are false.

One such false implication that stems from an extremely literal interpretation of the maxim "anecdotes are not evidence" is that _nothing at all_ can be learned from anecdotes.

Such a literal interpretation can be used to undermine the maxim itself. For instance, one could note a case in which a serial sex offender was caught due to the testimony of victims, which is necessarily anecdotal, and conclude that those who subscribe to "anecdotes are not evidence" would throw out this testimony, setting the sex offender free. This is such a morally repugnant proposition for so many that it could be used as a way to discredit those who are fond of the maxim "anecdotes are not evidence."

This literal interpretation can also be used as a foolish obstacle to understanding. For instance, if one hears stories from friends that a certain road is congested with traffic during rush hour, one might dismiss these stories, citing "anecdotes are not evidence." One would have no one to blame but oneself when one finds oneself stuck in traffic on the very same road, waiting for the rush hour congestion to clear.

Surely, because of these implications, this overly literal interpretation does not capture what the maxim "anecdotes are not evidence" is meant to convey. This is a flaw not just with this particular maxim, but with slogans in general, which threaten to become [shibboleths](political-rhetoric-as-shibboleths.html) when used incognizantly in this way.

The purpose of this article is to articulate the issues in using anecdotes as evidence in a more substantial way than can be done with a pithy maxim. It begins by discussing the sort of inference for which anecdotes are entirely useless, and this is balanced with later discussion of valid uses of anecdotes.


## Misuses of Anecdotes

Anecdotal evidence is useless for two kinds of inference: inference about a larger population and inference about cause and effect. 

### Inference about a Larger Population
 
While the prevalence or magnitude of a variable among some number of individuals that can be directly observed might sometimes be of interest, interesting questions often pertain to a larger population than those that are directly observed. For instance, an epidemiologist is usually professionally interested in how many people contracted the seasonal flu in a given geographic area, not how many of the epidemiologist's friends contracted the seasonal flu. This is a question about a larger population, i.e., all the people in the given geographic area, that is based on a smaller, representative sample, e.g., surveys, hospital records, etc. Anecdotes shed no light on these kinds of questions.

### Inference about Cause and Effect

Practical questions often pertain to whether or not something causes an effect and the size of such an effect. For instance, in clinical trials, a potential therapy is given to volunteers in order to determine whether or not the therapy causes an improvement in a disease or an increase in survival time. It is not enough to know how many people receiving the treatment improve or to what extent they improve. Indeed, there are many diseases from which people will often recover of their own accord. Rather, the question that is at issue in a clinical trial is whether or not the potential therapy _caused_ any measured improvement and what the _size_ of this _effect_ was. Again, anecdotes are no help in answering this kind of question.


## Flaws of Anecdotes as Evidence

Flaws in using anecdotes as a kind of evidence can broadly be grouped into two categories: statistical and psychological. The statistical flaws are what specifically preclude anecdotes from being useful for inference about a larger population and for inference about cause and effect, but do not prevent anecdotes from being useful in other ways. The psychological flaws affect anecdotal evidence no matter what the use, and so these flaws must be acknowledged and accepted during the valid uses of anecdotes articulated later.

### Statistical Flaws

#### Insufficient Sample Size

Returning to the example of the seasonal flu, suppose one is interested in how effective vaccination was in preventing individuals from contracting the flu in the United States during the 2019-2020 flu season. Suppose there are 10 friends and family that one keeps in touch with regularly. Of these 10, 6 were vaccinated against the flu, and 1 caught the flu this year. The 1 who caught the flu was not vaccinated. What estimate should one make of how effective this year's vaccine was?

A rough estimate for the probability of catching the flu when not vaccinated could be 1 / 4 = 25%. But what about the probability that someone who was vaccinated caught the flu? None of one's friends and family that were vaccinated caught the flu this year, so continuing this method of rough estimation leads to an estimate of 0 / 6 = 0%.

Thus, one might be tempted to say that, given these observations, this year's flu vaccine was absolutely effective. However, this is mistaken. Flu vaccines are effective at decreasing the risk that a vaccinated individual has in catching the flu, but they do not decrease the risk to zero. [@noauthor_vaccine_2020]

The issue this example highlights is that anecdotal evidence rarely consists of enough observations to make an inference to a larger population or to make an inference about cause and effect. Given a sample size of only 10, it is more likely than not that there would _not be a single individual_ in the sample who both was vaccinated and who caught the flu.[^envelope] However, in a larger sample of, for instance, 1,000 individuals, there would be many individuals who were vaccinated and who caught the flu.[^envelope-estimate]

[^envelope]: This is based on some back-of-the-envelope math. The U. S. Census Bureau estimate the population of the United States to be approximately 328,000,000 people. [@noauthor_quickfacts_nodate] The proportion of people in the United States who received the flu vaccine during the 2019-2020 season is estimated to be 63.8% for all age groups. [@noauthor_flu_2020] Therefore, there were approximately 209,300,000 vaccinated individuals and 118,700,000 unvaccinated individuals in the United States during the 2019-2020 flu season.

     The Centers for Disease Control and Prevention estimates there were 38,000,000 flu illnesses in the United States during the 2019-2020 flu season. [@noauthor_estimated_2020]
     
     A rough estimate of the relative risk for flu vaccination of 50% is reasonable. [@noauthor_vaccine_2020]

     This results in estimated probabilities of 17.0% of catching the flu among the unvaccinated and 8.5% of catching the flu among the vaccinated.

     The probability a randomly selected individual both was vaccinated and caught the flu is therefore 63.8% &times; 8.5% &approx; 5.42%, and the probability a random sample of 10 individuals does not contain someone who both was vaccinated and caught the flu is (1 &minus; 5.42%)<sup>10</sup> &approx; 57.3%. 

[^envelope-estimate]: Using the back-of-the-envelope calculations above, there would be around 54 such individuals in a random sample of 1,000.

In this case, the anecdotal evidence of one's friends and family does not consist of a large enough number of observations to calculate even a crude estimate of vaccine efficacy.[^power]

Furthermore, note that any estimate of the probability of catching the flu based on these anecdotes would be prone to wild fluctuations. If another unvaccinated friend happened to catch the flu during the 2019-2020 season, the estimated probability of unvaccinated individuals catching the flu would jump from 25% to 2 / 4 = 50%. This small change in the sample would result in a large change in the estimate about the larger population, which is an indication that the inference is susceptible to being thrown off due to chance.

[^power]: This is a plausible example of the phenomenon that anecdotal observations often do not comprise a sufficient sample size for inference, one which does not require knowledge of statistical methods. For the more mathematically minded, this phenomenon can be explored further by way of power computations at various sample sizes, which can be found in relevant statistics texts.

#### Unrepresentative Samples

Perhaps there is an individual so popular that polling the individual's friends and family results in a large enough number of observations to make an inference about a larger population or about cause and effect. Even if this were the case, another issue remains. The sample created from such polling is not _representative_ of a larger population. Instead, the sample is heavily biased towards the idiosyncracies of the individual in question.

Returning to the example of flu vaccine efficacy in the United States during the 2019-2020 season, suppose that a particularly extroverted individual keeps in regular contact with not just 10, but 200 friends and family. However, suppose the extroverted individual caught the flu during the 2019-2020 season.

In this case, the sample might be large enough for estimation of vaccine efficacy, but this sample will be biased because the extroverted individual was in contact with the 200 other people in the sample and so exposed them to the flu virus. Therefore, the prevalence of flu illness in this sample is expected to be higher than in the general population, which includes individuals who had no direct exposure to the flu virus. Because of this, any estimations regarding the _size_ of the protective effect _caused_ by the vaccine will be thrown off.

This phenomenon is likely to occur whenever sampling is based on personal associations. Another example comes from attempts to infer the prevalence of political affiliations based on a particular individual's social network. Most voters in the United States are registered as either Republican or Democrat. Because human beings tend to conform to those around them and to seek out those with similar views, if one starts with a registered Republican, one will likely find a higher proportion of registered Republicans among that individual's friends and family. Likewise, if one starts with a registered Democrat, one will likely find a higher proportion of registered Democrats among that individual's friends and family. Neither of these samples will be representative of the _larger population_ of the United States.

##### The Fallacy of Celebrated Cases

This issue is even worse for anecdotes that come not from personal associations, but by way of the news media. Much of what qualifies a story as news is that it is rare, unusual, or shocking enough to be of interest. Thus, news stories collectively form an _intentionally_ unrepresentative sample of what is happening in a larger population. This phenomenon was illustrated dramatically by the media frenzy around shark attacks in 2001.

While shark attacks on humans can result in a personal tragedy of injury or death for those involved that should neither be minimized nor made light of, the media representation of shark attacks in 2001 was misleading and irresponsible. A particularly graphic shark attack case was covered on major news media outlets in August of 2001. This was soon followed by story after story of sharks attacking humans. _Time_ magazine ran a cover story labeling the summer of 2001 the "Summer of the Shark."

![
_The July 30, 2001 cover of_ Time _magazine, which labeled the summer of 2001 the "Summer of the Shark."_
](/images/summer-of-the-shark.jpg)

This created an impression that shark attacks were increasing at an alarming rate during 2001 and that shark attacks were a particularly prevalent risk. However, it was soon discovered that 2001 had only an average number of shark attacks; indeed, the number of shark attacks and number of fatalities from shark attacks was actually less in 2001 than in 2000. [@noauthor_summer_2002]  

The so-called "Summer of the Shark" was not a sudden and pronounced increase in shark attacks, but a sudden and pronounced increase in the coverage of shark attacks. However, shark attacks are infrequent compared with other risks humans expose themselves to on a daily basis, so this spike in news coverage encouraged unsubstantiated fears. Nonetheless, the sensational coverage of shark attacks during 2001 did not end until the September 11, 2001 terrorist attacks took over the news cycle. Since then, the so-called "Summer of the Shark" has become an object lesson in bad journalism. [@dempsey_summer_2016]

[...]

#### Summary

Using anecdotes as evidence is flawed in two ways pertaining to statistical inference: anecdotes constitute sample sizes that are often too small to make precise estimates and are prone to wild fluctuations, and anecdotes form unrepresentative samples that throw off any estimation based on them due to bias. For these reasons, anecdotes are not useful at all for conclusions about a larger population and for conclusions about cause and effect. 

In addition to these statistical concerns, there are other flaws in anecdotes as evidence pertaining to how human minds work.

### Psychological Flaws

Contrary to popular belief, human memory does not "work like a video camera, accurately recording the events we see and hear so that we can review and inspect them later," as 63% of respondents in a demographically representative sample of 1,500 people in the United States believed in a recent telephone poll. [@simons_what_2011] Instead, human memory is flawed. People often fail to remember true things about past experiences or believe they remember false things about past experiences. Furthermore, the social experience of retelling memories can influence how past events are remembered.

#### Flaws of Memory Recall

The psychological literature around the topic of memory is quite large, and a full review of what has been learned about the fallibility of memory recall is beyond the scope of this article. Instead, this article summarizes a few seminal experiments in the field in order to establish the core point that memory recall, according to the empirical evidence, is quite fallible.

##### Misinformation Effect

The work of of psychologist Elizabeth F. Loftus is a particularly conspicuous part of the body of research on memory fallibility as it relates to anecdotal evidence, in part because much of this work has specifically focused on issues with eyewitness testimony and because of her engagement with the legal system, testifying as an expert witness in numerous high profile cases.

An early experiment of hers examined 45 students at the University of Washington who were shown the same video of a traffic accident. [@loftus_reconstruction_1974] The test subjects were then asked to estimate how fast the cars were going at the time of the accident, but the question was phrased using different words such as "smashed," "collided," "bumped," "hit," or "contacted." The mean estimated speed, averaged over different test subjects, for those asked with the word "smashed" was 40.8 miles per hour, whereas the mean estimated speed was only 31.8 miles per hour for those asked with the word "contacted."

More remarkably, in a follow-up, similar experiment with 150 student participants, the word choice of "smashed" versus "hit" appeared to affect whether a detail was falsely remembered. The 150 test subjects were shown a video of a multiple car traffic accident. After watching the video, 50 test subjects were given a questionnaire that included the question "About how fast were the cars going when they smashed into each other?" Another 50 test subjects were given a similar questionnaire that asked how fast the cars were going when they "hit" each other, and a control group of another 50 test subjects were not asked about the speed of the cars.

All the test subjects were given a second questionnaire 1 week later in which they were asked whether they recalled seeing broken glass. There was no broken glass in the original video. Among those who were asked the "smashed" question, 16 of the 50 (32%) replied "yes" to seeing broken glass, whereas only 7 out of 50 (14%) of those asked the "hit" question and 6 out of 50 (12%) of the control group reported seeing broken glass. This effect of an increased probability of incorrectly remembering broken glass was mediated in part by the greater speed estimates of the "smashed" group, but there was still an effect that averaged to 12 percentage points independent of speed estimate.

This phenomenon in which subjects' subsequent recall could be modified was further investigated with several experiments that focused on the effect of leading questions. [@loftus_leading_1975] In one experiment, 150 students at the University of Washington were shown another video of an automobile accident. The test subjects were given a questionnaire immediately following watching the video, in which half were given the question "How fast was the white sports car going when it passed the barn while traveling down the country road?" while half were given a similar question that did not mention a barn. There was, in fact, no barn in the video.

A week later, the test subjects were given another questionnaire that included the question "Did you see a barn?" Of the ones who had a variant of the earlier questionnaire that mentioned a barn, 13 out of 75 (17.3%) replied that they had seen a barn, whereas only 2 out of 75 (2.7%) whose earlier questionnaire did not mention a barn reported having seen a barn on the later questionnaire.

It is one thing to recall false details such as broken glass or a barn that was not originally there, but this research would go on to show that false memories of an entire experience that did not happen could be inculcated in test subjects.

In a one such experiment, 24 pairs of volunteers ranging in age from 18 to 53 years were recruited by University of Washington students. [@loftus_formation_1995] Each pair had an older "relative" volunteer who had knowledge of the younger "subject" volunteer. The subjects were given a booklet that contained 4 stories from their childhood experience. While all of the stories were based on knowledge provided by the relatives, 3 of the stories were true, and 1 was a false story about getting lost while on a shopping trip.

The booklet contained a cover letter that instructed subjects to write what they remembered about the events in the space provided or to indicate they did not remember the event if they did not recall it. The subjects were interviewed twice, with 1 to 2 weeks before each interview, and again asked to provide whatever details they could recall about each event, but during the interviews they were also asked to score the clarity of their memories on a scale from 1 to 10.

Subjects remembered 49 out of 72 (68%) of the total true events throughout the experiment. During the booklet phase of the experiment, 7 out of 24 (29%) of the total false events were remembered as having occurred, but 1 test subject changed her answer during the interview phase, decreasing this total to 6 out of 24 (25%).

The mean clarity rating was higher for the true events (6.3) than for the false events (2.8) during the first interview. However, during the second interview, mean clarity remained roughly the same for true events (6.3), but increased for the false events (3.6). Even after being told that 1 of the 4 events was fabricated, 5 out of the 24 (21%) identified a true event as the story they believed was invented instead of the actual false event.

The results of this and other similar experiments were timely in the 1990s because of criminal prosecutions based on individuals allegedly recalling repressed memories of childhood abuse, memories that were only discovered after extensive therapy sessions. Experments such as the one related above showed how at least some of such prosecutions were likely based on false memories inculcated by therapists inadvertently using similar methods as in the experiment. [@loftus_reality_1993]

##### Word Lists

While the research of Elizabeth Loftus and others had direct implications for the courtroom, this line of research focused on memories affected by misinformation encountered _after_ the original experience. [@loftus_planting_2005] Other lines of research explored false recall of memories not tainted in this way.

One tool useful for such lines of research are Deese-Roediger-McDermott (DRM) lists. [@roediger_creating_1995] These lists consist of some number of words that are all associated with a critical word that does not appear on the list. For instance, a DRM list might consist of the words "thread," "pin," "eye," "sewing," "sharp," "point," "pricked," "thimble," "haystack," "pain," "hurt," and "injection." The critical nonpresented word for this list is "needle."

In one experiment, DRM lists were prepared with 15 words each, and 14 lists were used in recall and recognition exercises with 30 undergraduate students at Rice University.[^extra-lists] For every list, each word was spoken out loud from a tape recording at a rate of about 1 word every 1.5 seconds. After each list was read aloud, for 2 minutes, half the test subjects did a free recall exercise writing down as many words as they could remember, and half the test subjects did math problems as a filler exercise. At the end of the exercises, each test subject had done the free recall exercise for 7 lists and had listened to, but not done a free recall exercise for 7 DRM lists.

[^extra-lists]: Actually, 16 DRM lists were presented, but 2 were dropped from the study.

Finally, the test subjects were given a recognition test that consisted of a written list of 96 words &ndash; 48 of which had been presented to them during the experiment &ndash; and asked to identify which words they had encountered and which they had not. The 48 nonpresented words on the recognition test included the 14 critical nonpresented words. For words that the test subjects identified as having been presented, they were additionally asked about their phenomenological experience: words were _remembered_ if the test subject could mentally relive the experience of encountering the word, and words were _known_ if not.

During the free recall, test subjects recalled 62% of the words presented to them. They mistakenly recalled the critical nonpresented words 55% of the time. This is even more remarkable because the rate at which presented words were recalled varied depending on their position on the lists, and presented words in positions 4 through 11 were recalled 47% of the time, a rate even lower than the critical nonpresented words.

During the recognition test, the critical unpresented words were falsely recognized 72% of the time for lists for which a free recall had not been done, and 81% of the time for lists for which a free recall had been done. About 53% of the critical unpresented words for non-recall lists were described as remembered rather than known, and 72% of the critical nonpresented words for recall lists were identified as remembered.

This experiment demonstrated that even without misinformation contaminating memory, human beings can be subject to systematic and measurable false recall. Furthermore, it suggested that all memory, even exercises as rote as remembering lists of words, is reconstructive, leveraging prexisting schemas of association already present in a mind before an experience is had. Finally, even in such a banal setting, a nontrivial proportion of false recall involved remembering rather than knowing, reliving an experience that never actually occurred.

#### Flaws of Serial Reproduction

Anecdotes are not just recalled from memory and told to one other person. Sometimes the person told an anecdote retells it to yet another person. Indeed, by the time one encounters it, an anecdote may have been retold any number of times. This is a situation not unlike a children's game called "telephone" in the United States and by many other names in other parts of the world.

In this game, one child is told a story. This child is then tasked with repeating it exclusively to a second child, often by whispering. The second child repeats it only to a third child, and so on, until a final child is told the story. At the end, the story that the final child tells is compared with the original story. The amusement of the game comes in discovering how the final version of the story has been mangled and altered from its original version.

In the psychological literature, this phenomenon is called "serial reproduction." This is in contrast to what is called "repeated reproduction" in which the same individual recalls a memory again and again. Several experiments throughout the twentieth century confirmed the moral of the telephone game, i.e., that serial reproduction is error prone and distorts information. More recently, a study quantified how much more error prone serial reproduction can be compared to repeated reproduction. [@roediger_bartlett_2014]

In this experiment, 60 undergraduate students at Washington University were presented with DRM word lists by way of computers, asked to do multiplication problems for 30 seconds, then prompted to recall the DRM word list.[^social] For the repeated reproduction portion of the experiment, a test subject was simply asked to recall the original DRM word list 4 times in this manner. For the serial reproduction portion of the experiment, the list recalled by one test subject was given to another test subject. These serially reproduced lists were passed along 4 different test subjects, with the first given the original DRM list and the next 3 given the previous test subject's recalled list.

[^social]: Serial reproduction is just one aspect of the social phenomena of memory. By using a computer program, the experiment by @roediger_bartlett_2014 abstracted away many of the social influences on memory. These social influences have complex effects, with some of them aiding in memory recall and some of them causing more errors in memory. [@hirst_remembering_2012]

The mean proportion of words correctly recalled from the original DRM word lists, averaged across test subjects, remained relatively constant around 50% during repeated reproduction. However, the mean proportion of words correctly recalled declined at each step in serial reproduction, starting around 50% and ending up at just above 20% after 4 iterations. Furthermore, the mean proportion of recalled words that were actually falsely recalled critical nonpresented words remained relatively constant around 5% during repeated reproduction, but increased at each step during serial reproduction, winding up at over 10% after 4 iterations.

What is interesting about the worse performance of serial reproduction in this experiment is that at each step in the serial reproduction, test subjects tended to perform _better_ than in the previous step, inasmuch as they were recalling a greater proportion of the lists that they had been presented. This should not be surprising as each step in serial reproduction tended to start with a shorter list than the previous, and it is generally easier to remember less things.

What caused the overall worse performance of serial reproduction over repeated reproduction in this experiment was that each step in serial reproduction carried over the mistakes from the previous steps. Once a word that really did appear on the original DRM world list was forgotten, it would not appear on the input list for subsequent serial steps and thus be lost for the rest of the process. Once a critical nonpresented word was falsely recalled, it would be put on the input list for the subsequent serial step and so be indistinguishable from words that actually appeared on the original list.

#### Implications

This highlights a danger in the retelling of anecdotes. Specifically, any issues of false recall are compounded as anecdotes are told and retold along a serial chain. Since anecdotes told by the original observer of the anecdote ought to be scrutinized for reasons examined in the previous section, anecdotes retold secondhand thus ought to be treated with even more scrutiny.

## Uses of Anecdotes

### Investigation of Specific, Singular Incident

### Counterexample to Universal Assertion

### Precipitation of Further Investigation

### Illustrative Example of Phenomenon Supported by Other Evidence

## Conclusion


## Citations

::: {#refs}
:::


## Footnotes
